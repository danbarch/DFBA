XXXXXXXXX Following is for dfba_beta_descriptive XXXXXXX

dfba_beta_descriptive<-function(a,b,hdiprob=.95){
#function computes point and interval estimates for a beta distribution
if ((hdiprob>1)|(hdiprob<0)){
hdiprob=.95
message("The hdiprob must be a value <1 and >0. The default value was taken to be .95")}
else {}

if ((a<=0)|(b<=0)|(is.na(a))|(is.na(b))) {
stop("Both the a and b shape parameters for a beta must be nonnegative.")} else {}

phimean=a/(a+b)
phimedian=qbeta(.5,a,b)
if ((a>1)&(b>1)){
phimode=(a-1)/(a+b-2)}
else {
phimode=NA}
m1="Centrality Statistics"
cat(m1,"are :","\n")
cat("Mean","    ","Median","    ","Mode","\n")
cat(phimean," ",phimedian," ",phimode,"\n")
cat(" ","  ","\n")

hdiper=100*hdiprob
m2=as.character(hdiper)
cat(m2,"percent interval limits are :","\n")
cat("Interval with equal tails",":","\n")
qlequal=qbeta((1-hdiprob)/2,a,b)
qhequal=qbeta(hdiprob+((1-hdiprob)/2),a,b)
cat(qlequal," ",qhequal,"\n")
alphaL=seq(0,1-hdiprob,(1-hdiprob)/1000)
qL=qbeta(alphaL,a,b)
qH=qbeta(hdiprob+alphaL,a,b)
diff=qH-qL
I=1
mindiff=min(diff)
while (diff[I]>mindiff){
I=I+1}
qLmin=qL[I]
qHmax=qH[I]
cat("Highest Density Interval",":","\n")
cat(qLmin," ",qHmax,"\n")

x=seq(0,1,.005)
y=dbeta(x,a,b)
plot(x,y,type="l",xlab="phi value",ylab="probability density")
}


XXXXXXXXXXX Following code is for dfba_beta_bayes_factor XXXXXXX

dfba_beta_bayes_factor<-function(a,b,method,null,a0=1,b0=1){
#program to find the Bayes factor for beta distribution
#method="interval" or method="point" are the only options
#null is a vector of length two for method="interval" and
#these two values are respectively the lower and upper limits
#of the null hypothesis interval. When method="point"
#the vector null is a single point value for the point null hypthosis.

if ((a<=0)|(b<=0)|(is.na(a))|(is.na(b))) {
stop("Both the a and b shape parameters for the posterior beta must be >0.")}
else {}

if ((a0<=0)|(b0<=0)|(is.na(a0))|(is.na(b0))){
stop("Both the a0 and b0 shape parameters for the prior beta must be >0.")}
else {}

x=seq(0,1,.005)
y=dbeta(x,a,b)
y0=dbeta(x,a0,b0)
plot(x,y,type="l",xlab="phi",ylab="probability density",main="posterior solid; prior dashed")
lines(x,y0,type="l",lty=2)

if (method=="interval"){
#beginning the interval BF section

if (length(null)!=2){
stop("The null vector for an interval null hypothesis must be 2 and consist of the lower and upper values for the null hypothesis, which must be within the [0,1] interval.")} else {}

if ((null[1]<0)|(null[1]>1)|(null[1]>=null[2])|(null[2]>1)){
stop("The lower and upper limits in null[1] and null[2] are not a proper subset of the [0,1] interval.")}
else {}

m1="The null hypothesis is that the phi parameter is within the interval of"
cat(m1,":","\n")
cat(null[1]," ",null[2],"\n")
pH0up=pbeta(null[2],a0,b0)
pH0lo=pbeta(null[1],a0,b0)
pH0=pH0up-pH0lo
m2="Prior and posterior probabilities for the null are"
cat(m2,":","\n")
postup=pbeta(null[2],a,b)
postlo=pbeta(null[1],a,b)
postH0=postup-postlo
cat("Prior","   ","Posterior","\n")
cat(pH0," ",postH0,"\n")
cat(" ","  ","\n")

m3="Prior and posterior probabilities for the alternative hypothesis"
cat(m3,":","\n")
cat("Prior","  ","Posterior","\n")
pH1=1-pH0
postH1=1-postH0
cat(pH1,"   ",postH1,"\n")
cat(" ","  ","\n")
m4="Bayes factor BF10 is for the alternative over the null"
m5="Bayes factor BF01 is for the null over the alternative"

if(pH0>=postH0){
 cat(m4," ","\n")} else {
 cat(m5," ","\n")}

if (pH0>=postH0) {
  if(postH0==0){
    cat("Bayes factor is approaching infinity"," ","\n")}
    else {
    BF10=((1/postH0)-1)/((1/pH0)-1)
    cat(BF10," ","\n")}

 } else {
  if (postH0==1) {
   cat("Bayes factor is approaching infinity"," ","\n")}
   else {
   BF01=((1/pH0)-1)/((1/postH0)-1)
   cat(BF01," ","\n")}}
#end of method="interval"
return(cat(" ","  ","\n"))} else {}

if (method=="point"){
#beginning the point BF section

if (length(null)!=1) {
stop("The null vector for a point hypothesis must have a value that is within the [0,1] interval")}
else {}

if((null[1]<0)|(null[1]>1)){
stop("The null point must be within the [0,1] interval")}
else {}

m6="The null hypothesis is the point"
cat(m6,":","\n")
cat(null[1]," ","\n")
cat(" ","  ","\n")
m7="Prior and posterior probability densities at the null point are"
cat(m7,":","\n")
cat("Prior","   ","Posterior","\n")
dpriorH0=dbeta(null[1],a0,b0)
dpostH0=dbeta(null[1],a,b)
cat(dpriorH0,"  ",dpostH0,"\n")
cat(" ","  ","\n")
m8="Bayes factor BF10 is for the alternative over the null"
m9="Bayes factor BF01 is for the null over the alternative"
if (dpriorH0>=dpostH0){
cat(m8," ","\n")} else {
cat(m9," ","\n")}

if (dpriorH0>=dpostH0) {
  if (dpostH0==0) {
  cat("Bayes factor is approaching infinity"," ","\n")}
  else {
  BF10=dpriorH0/dpostH0
  cat("Bayes factor BF10 is",":","\n")
  cat(BF10," ","\n")}
 }
else{
  if (dpriorH0==0){
  cat("Bayes factor is approaching infinity"," ","\n")}
  else {
  BF01=dpostH0/dpriorH0
  cat("Bayes factor BF01 is",":","\n")
  cat(BF01," ","\n")}
 } 
#end of method="point"
return(cat(" ","  ","\n"))} else {}

if ((method!="interval")&(method!="point")){
stop("method must be included and it must be either the words interval or point")}
else {} 

}

XXXXXXXX Following is the code for dfba_median_test XXXXXXX

dfba_median_test<-function(Y1,Y2,a0=1,b0=1){
#Median test for two independent groups with continuous measurements
Etemp=Y1
Ctemp=Y2
jc=0
for (j in 1:length(Y1)){
if (is.na(Etemp[j])){} else {
jc=jc+1
Y1[jc]=Etemp[j]}
}
Y1=Y1[1:jc]

kc=0
for (k in 1:length(Y2)){
if (is.na(Ctemp[k])){} else {
kc=kc+1
Y2[kc]=Ctemp[k]}
}
Y2=Y2[1:kc]
#Above code delete NA scores.

Y<-c(Y1,Y2)
med=median(Y)
cat("Overall median is",":","\n")
cat(med," ","\n")
cat(" ","  ","\n")

l1=length(Y1)
l2=length(Y2)
A1above=0
A1below=0
for (I in 1:l1){
if (Y1[I]>med){A1above=A1above+1} else {A1below=A1below+1}}
A2above=0
A2below=0
for (I in 1:l2){
if (Y2[I]>med){A2above=A2above+1} else {A2below=A2below+1}}

cat("Frequencies above the median are",":","\n")
cat("Y1","   ","Y2","\n")
cat(A1above,"   ",A2above,"\n")
cat("Frequencies at or below the median are",":","\n")
cat("Y1","   ","Y2","\n")
cat(A1below,"   ",A2below,"\n")


a=A1above+a0
b=A2above+b0
Y1baserate=l1/(l1+l2)
probY1hi=1-pbeta(Y1baserate,a,b)
Y2baserate=1-Y1baserate
cat("Respective base rates for Y1 and Y2 responses are",":","\n")
cat(Y1baserate," ",Y2baserate,"\n")
cat(" ","  ","\n")

cat("Following is the analysis of responses above the median",":","\n")
probY2hi=1-pbeta(Y2baserate,b,a)
if (probY1hi>=probY2hi) {
cat("Posterior probability that Y1 exceeds base rate is",":","\n")
cat(probY1hi," ","\n")
 
 postodds=probY1hi/(1-probY1hi)
 priorY1hi=1-pbeta(Y1baserate,a0,b0)
 priorodds=priorY1hi/(1-priorY1hi)
 BF=postodds/priorodds
 cat("Prior probability that Y1 exceeds base rate is",":","\n")
 cat(priorY1hi," ","\n")
 cat("Bayes factor that Y1>median exceeds its base rate is",":","\n")
 cat(BF," ","\n")} else {

 cat("Posterior probability that Y2 exceeds base rate is",":","\n")
 cat(probY2hi," ","\n")
 postodds=probY2hi/(1-probY2hi)
 priorY2hi=1-pbeta(Y2baserate,b0,a0)
 priorodds=priorY2hi/(1-priorY2hi)
 BF=postodds/priorodds
 cat("Prior probability that Y2 exceeds base rate is",":","\n")
 cat(priorY2hi," ","\n")
 cat("Bayes factor that Y2>median exceeds its base rate is",":","\n")
 cat(BF," ","\n") }
}

XXXXXXX Following is the code for dfba_mann_whitney XXXXXXX

dfba_mann_whitney<-
function(E,C,method,priorvalues=rep(1/200,200)){
#testing if E and C vectors are valid after removing
#NA values from the two vectors
Etemp=E
Ctemp=C
jc=0
for (j in 1:length(E)){
if (is.na(Etemp[j])){} else {
jc=jc+1
E[jc]=Etemp[j]}
}
E=E[1:jc]

kc=0
for (k in 1:length(C)){
if (is.na(Ctemp[k])){} else {
kc=kc+1
C[kc]=Ctemp[k]}
}
C=C[1:kc]

nE=length(E)
nC=length(C)
if ((nE==0)|(nC==0)){
 stop("The E and C vectors must have a length greater than 0.")} else {}
Emean=mean(E)
Cmean=mean(C)
cat("E mean","  ","C mean","\n")
cat(Emean,"  ",Cmean,"\n")
cat("n_E","  ","n_C","\n")
cat(nE,"   ",nC,"\n")
cat(" ","   ","\n")

#following code finds U_E and U_C
  UE_vector<-rep(NA, length(E)) # UE counter
  UC_vector<-rep(NA, length(C)) # UC counter 
for (i in 1:length(E)){
    UE_vector[i]<-sum(E[i]>C)
  }
for (j in 1:length(C)){
 UC_vector[j]<-sum(C[j]>E)
}
 UE=sum(UE_vector)
 UC=sum(UC_vector) 
 cat("UE","  ","UC","\n")
 cat(UE,"   ",UC,"\n")
 cat(" ","   ","\n")

if (method=="small"){
m1lable<-"Following is based on 30000 Monte Carlo samples"
    m2lable<-" with discrete prob. values."
    cat(m1lable,m2lable,"\n")
  if (length(priorvalues)!=200) {
  stop("priorvalues must have a length of 200 or use the default by omitting priorvalues")}
    else {}
  totprior=sum(priorvalues)
  if ((totprior>1.01)|(totprior<.99)){
  priorvalues=rep(1/200,200)
  message("User's prior did not sum to 1, so a flat prior was used instead.")} else {}


  XE=seq(1, length(E), 1)
  XC=seq(1, length(C), 1)
  fomega<-rep(0.0,200)
  n_samples=30000
  

for (j in 1:200){
 omega=(1/400)+(j-1)*(1/200)
 komega=(1-omega)/omega

for (k in 1:n_samples){
 Uz<-rep(NA, length(E))
 XE<-rexp(length(E), rate=komega)
 XC<-rexp(length(C), rate = 1)

for (i in 1:length(E)){
 Uz[i]<-sum(XE[i]>XC)
}

if(sum(Uz) == UE) {fomega[j] = fomega[j]+1} else {}
 }
}

tot=sum(priorvalues*fomega)
omegapost=(priorvalues*fomega)/tot
phiv=rep(0.0,200)
    for (j in 1:200){
      phiv[j]=(1/400)+(j-1)*(1/200)}
    postdis<-data.frame(phiv,omegapost)

 #Folowing finds the mean of the posterior omega distribution
    #and provides a plot of the distribution.
    omegabar=sum(phiv*omegapost)
    print("mean for omega based on Monte Carlo sampling is:")
    print(omegabar)
    plot(phiv,omegapost,type="l",xlab="omega",ylab="posterior discrete probabilities",main="Based on Monte Carlo Samples")
    #The following finds the poserior cumulative distribution and outputs these values.
    cum_omega=cumsum(omegapost)
    omega_E=phiv
    cumdis<-data.frame(omega_E,cum_omega)
    #The prH1 is the probability that phi_w is greater than .5.
    prH1=1-cum_omega[round(100)]
    print("probability that omega exceeds .5 is:")
    print(prH1)
    #Following finds the Bayes factor for omega being greater than .5.
    cum_prior=cumsum(priorvalues)
    priorprH1=1-cum_prior[round(100)]
    if ((prH1==1)|(priorprH1==0)){
        BF10=2*n_samples
      print("Bayes factor BF10 for omega >.5 is estimated to be greater than:")
      print(BF10)} else {
        BF10=(prH1*(1-priorprH1))/(priorprH1*(1-prH1))
        print("Bayes factor BF10 for omega>.5 is:")
        print(BF10)}
    #Following provides output of key statistics.
    #list(posterior_cum_distribution=cumdis)
    #m1X=" "
    #m2X=" "
  return(list(posterior_discrete_values=omegapost,posterior_cum_distribution=cumdis))}
   else {}

if (method=="large"){
   m1L<-"Following is a beta approximation for omega"
   m2L<-"which is accurate for n>14 in both groups"
   cat(m1L,m2L,"\n")
   cat(" ","   ","\n")
  if (length(priorvalues)!=2) {
  stop("priorvalues must have two value which are a0 and b0")}
    else {}
  if ((priorvalues[1]<=0)|(priorvalues[2]<=0)){
  stop("both of the shape parameters for priorvalues must be >0. Use 1 for each for a flat prior.")}           
  else {}

#Following is a Lagrange interpolation method to find posterior a and b 
#shape parameters for the beta approximation to the omega_E distribution
xs=UE/(UE+UC)
if (xs>=.5) {x=xs} else {x=1-xs}
nH=(2*nE*nC)/(nE+nC)
y5=(nH^1.1489)/(.4972+(nH^1.1489))
w4=.8-(1/(1+(1.833*nH)))
w3=.6-(1/(1+(2.111*nH)))
w2=.4-(1/(1+(2.520*nH)))
w1=.2-(1/(1+(4.813*nH)))
y4=(y5*w4)+(1-w4)*.5
y3=(y5*w3)+(1-w3)*.5
y2=(y5*w2)+(1-w2)*.5
y1=(y5*w1)+(1-w1)*.5
Y=c(.5,y1,y2,y3,y4,y5)
La0=252-(1627*x)+((12500*x^2)-(15875*x^3)+(10000*x^4)-(2500*x^5))/3
La1=-1050+((42775*x)/6)-(38075*.5*x^2)+((75125*x^3)-(48750*x^4)+(12500*x^5))/3
La2=1800-(12650*x)+((104800*x^2)-(142250*x^3)+(95000*x^4)-(25000*x^5))/3
La3=-1575+(11350*x)+((-96575*x^2)+(134750*x^3)-(92500*x^4)+(25000*x^5))/3
La4=700+(14900*x^2)+(15000*x^4)-((15425*x)+(63875*x^3)+(12500*x^5))/3
La5=-126+(1879*.5*x)+((-16625*.5*x^2)+(12125*x^3)-(8750*x^4)+(2500*x^5))/3
LA=c(La0,La1,La2,La3,La4,La5)
ombar=sum(Y*LA)
absum=nH*(1.028+(.75*x))+2
a=ombar*absum
b=(1-ombar)*absum
omegabar=ombar
if (xs<.5){
  a=(1-ombar)*absum
  b=ombar*absum
  omegabar=1-ombar} else {}
na=a-1
nb=b-1
apost=priorvalues[1]+na
bpost=priorvalues[2]+nb
cat("posterior a"," ","posterior b","\n")
cat(apost,"   ",bpost,"\n")
cat(" ","  ","\n")

a=apost
b=bpost
x=seq(0,1,.005)
y=dbeta(x,a,b)
y0=dbeta(x,priorvalues[1],priorvalues[2])
plot(x,y,type="l",xlab="omega_E",ylab="probability density",main="posterior solid; prior dashed")
lines(x,y0,type="l",lty=2)

postmean=a/(a+b)
postmedian=qbeta(.5,a,b)
mc1="posterior mean"
mc2="posterior median"
cat(mc1,"  ",mc2,"\n")
cat(postmean," ",postmedian,"\n")

qlequal=qbeta(.025,a,b)
qhequal=qbeta(.975,a,b)

met1="equal-tail 95-percent limit values are"
met2=":"
cat(met1,met2,"\n")
cat(qlequal," ",qhequal,"\n")

alphaL=seq(0,.05,.05/1000)
qL=qbeta(alphaL,a,b)
qH=qbeta(.95+alphaL,a,b)
diff=qH-qL
I=1
mindiff=min(diff)
while (diff[I]>mindiff){
I=I+1}
qLmin=qL[I]
qHmax=qH[I]
mhdi1="95-percent highest density limits are"
mhdi2=":"
cat(mhdi1,mhdi2,"\n")
cat(qLmin," ",qHmax,"\n")

prH1=1-pbeta(.5,a,b)
#print("Posterior probabilty that omega_E > .5 is:")
#print(prH1)
priorprH1=1-pbeta(.5,priorvalues[1],priorvalues[2])
#print("Prior probabilty that phi_w > .5 is:")
#print(priorprH1)
mH11="assessing the probability that omega_E > .5"
mH12=" "
cat(mH11,mH12,"\n")
mH1prior="prior"
mH1post="posterior"
cat(mH1prior,"  ",mH1post,"\n")
cat(priorprH1,"  ",prH1,"\n") 
if ((prH1==1)|(priorprH1==0)){
minf1="Bayes factor BF10 for omega_E >.5 is approaching"
minf2="infinity"
cat(minf1,minf2,"\n")} else {
BF10=(prH1*(1-priorprH1))/(priorprH1*(1-prH1))
mBF1="Bayes factor BF10 for omega_E > .5"
mBF2="is"
cat(mBF1,mBF2,"\n")
print(BF10)}
    m1X=" "
    m2X=" "
  return(cat(m1X,m2X,"\n"))
} else {}

if ((method!="large")&(method!="small")) {
stop("method must be included, and it must equal either the word small or large")} else {}

}


XXXXXXXX Following is the code for dfba_wilcoxon

dfba_wilcoxon<-
function(Y1,Y2,method,priorvalues=rep(1/200,200)){
Etemp=Y1
Ctemp=Y2
jc=0
for (j in 1:length(Y1)){
if (is.na(Etemp[j])){} else {
jc=jc+1
Y1[jc]=Etemp[j]}
}
Y1=Y1[1:jc]

kc=0
for (k in 1:length(Y2)){
if (is.na(Ctemp[k])){} else {
kc=kc+1
Y2[kc]=Ctemp[k]}
}
Y2=Y2[1:kc]
Y1mean=mean(Y1)
Y2mean=mean(Y2)
cat("Y1 mean","   ","Y2 mean","\n")
cat(Y1mean,"  ",Y2mean,"\n")
l1=length(Y1)
l2=length(Y2)
if (l1!=l2) {
 stop("Y1 and Y2 must have the same length. This function is within-block data with no missing values.")} else {}

dt=Y1-Y2
d=Y1
jc=0
 for (j in 1:l1){
 if (is.na(dt[j])){} else {
   jc=jc+1
   d[jc]=dt[j]}
 } 
d=d[1:jc]
l1=jc

if (l1<3){
 stop("There are not enough values in the Y1 and Y2 vector for meaningful results.")} else {}

#The following code computes the within-block difference scores, and finds the
  #number of blocks where the difference scores are nonzero (within a trivial rounding error).
    sdd=sd(d)
    IC=0
    for (I in 1:l1){
      if (abs(d[I])<=sdd/30000){IC=IC} else {IC=IC+1}}
    n=IC
  #The following code deals with the case where all differnces are trivially close to 0.  
    if (n==0){stop("Y1 and Y2 differences are all trivial")} else {}

  #The following finds the Tplus and Tminus stats and the number of nonzero blocks
    dt=(seq(1,n,1))*0
    IC=0
    for (I in 1:l1){
      if (abs(d[I])<=sdd/30000){IC=IC} else {
        IC=IC+1
        dt[IC]=d[I]}}
    dta=(seq(1,n,1))*0
    for (I in 1:n){
      dta[I]=abs(dt[I])}
    #The vector dtar is for the ranks of the absolute-value d scores; whereas
    #the dta vector is for the absolute-value of the d scores, and dtars is
    #the vector of signed rank scores. 
    dtar=rank(dta)
    dtars=dtar*dt/dta
    #The following computes the Tplus and Tminus statistics
    tplus=0
    for (I in 1:n){
      if (dtars[I]>0){tplus=tplus+dtar[I]} else {tplus=tplus} }
    tneg=(n*(n+1)*.5)-tplus
    cat("n","  ","T_plus","  ","T_negative","\n")
    #desstat<-c(n,tplus,tneg)
    #print(desstat)
    cat(n,"  ",tplus,"      ",tneg,"\n")

if (method=="small"){
m1lable<-"Following is based on 30000 Monte Carlo samples"
    m2lable<-" with discrete prob. values."
    cat(m1lable,m2lable,"\n")
  if (length(priorvalues)!=200) {
  stop("priorvalues must have a length of 200 or use the default by omitting priorvalues")}
    else {}
totprior=sum(priorvalues)
if ((totprior>1.01)|(totprior<.99)){
priorvalues=rep(1/200,200)
message("User's prior did not sum to 1, so a flat prior was used instead.")} else {}


samples=30000
priorvector=priorvalues
fphi<-rep(0.0,200)
    for (j in 1:200){
      phi=1/(400)+(j-1)*(1/200)
      for (k in 1:samples){
        tz=sum((1:n)*rbinom(n, 1, phi))
        
        if(tz==tplus) {
          fphi[j]=fphi[j]+1.0
        } else{
          fphi[j]=fphi[j]
        }
      }
    }
    #The tot value below is the denominator of the discrete analysis,
    #phipost is the vector for the posterior distribution.
    tot=sum(priorvector*fphi)
    phipost=(priorvector*fphi)/tot
    phiv=rep(0.0,200)
    phibar=0.0
    for (j in 1:200){
      phiv[j]=(1/400)+(j-1)*(1/200)
      phibar=phibar+(phiv[j]*phipost[j])}
    print("mean for phi_w is:")
    print(phibar)
    postdis<-data.frame(phiv,phipost)
   
    plot(phiv,phipost,type="l",xlab="phi_w",ylab="posterior discrete probabilities",main="Based on Monte Carlo Samples")
    #The following finds the poserior cumulative distribution and outputs these values.
    cum_phi=cumsum(phipost)
    phi_w=phiv
    cumdis<-data.frame(phi_w,cum_phi)
    #The prH1 is the probability that phi_w is greater than .5.
    prH1=1-cum_phi[round(100)]
    print("probability that phi_w exceeds .5 is:")
    print(prH1)
    #Following finds the Bayes factor for phi_w being greater than .5.
    cum_prior=cumsum(priorvector)
    priorprH1=1-cum_prior[round(100)]
    if ((prH1==1)|(priorprH1==0)){
        BF10=2*samples
      print("Bayes factor BF10 for phi_w >.5 is estimated to be greater than:")
      print(BF10)} else {
        BF10=(prH1*(1-priorprH1))/(priorprH1*(1-prH1))
        print("Bayes factor BF10 for phi_w>.5 is:")
        print(BF10)}
    #Following provides output of key statistics.
    #list(posterior_cum_distribution=cumdis)
    #m1X=" "
    #m2X=" "
  return(list(posterior_discrete_values=phipost,posterior_cum_distribution=cumdis))}

if (method=="large"){
   m1L<-"Following is based on beta approximation for phi_w"
   m2L<-"which is highly accurate for n>24"
   cat(m1L,m2L,"\n")
   cat(" ","   ","\n")
  if (length(priorvalues)!=2) {
  stop("priorvalues must have two value which are a0 and b0")}
    else {}
  if ((priorvalues[1]<=0)|(priorvalues[2]<=0)){
  stop("both of the shape parameters for priorvalues must be >0. Use 1 for each for a flat prior.")} else {} 

#The following code finds the shape parameters of a beta 
#distribution that approximates the posterior distribution
#for the phi_w parameter
na0=priorvalues[1]-1
nb0=priorvalues[2]-1
term=(3*tplus)/((2*n)+2)
na=term+.25
nb=(((3*n)-1)/4)-term
a=na+na0+1
b=nb+nb0+1
x=seq(0,1,.005)
y=dbeta(x,a,b)
y0=dbeta(x,priorvalues[1],priorvalues[2])
plot(x,y,type="l",xlab="phi_w",ylab="probability density",main="posterior solid; prior dashed")
lines(x,y0,type="l",lty=2)

postmean=a/(a+b)
postmedian=qbeta(.5,a,b)
ms1="posterior shape parameters are"
ms2=":"
cat(ms1,ms2,"\n")
cat(a,"  ",b,"\n")
cat("  ","   ","\n")
mc1="posterior mean"
mc2="posterior median"
cat(mc1,"  ",mc2,"\n")
cat(postmean," ",postmedian,"\n")

qlequal=qbeta(.025,a,b)
qhequal=qbeta(.975,a,b)

met1="equal-tail 95-percent limit values are"
met2=":"
cat(met1,met2,"\n")
cat(qlequal," ",qhequal,"\n")

alphaL=seq(0,.05,.05/1000)
qL=qbeta(alphaL,a,b)
qH=qbeta(.95+alphaL,a,b)
diff=qH-qL
I=1
mindiff=min(diff)
while (diff[I]>mindiff){
I=I+1}
qLmin=qL[I]
qHmax=qH[I]
mhdi1="95-percent highest density limits are"
mhdi2=":"
cat(mhdi1,mhdi2,"\n")
cat(qLmin," ",qHmax,"\n")

prH1=1-pbeta(.5,a,b)
#print("Posterior probabilty that phi_w > .5 is:")
#print(prH1)
priorprH1=1-pbeta(.5,na0+1,nb0+1)
#print("Prior probabilty that phi_w > .5 is:")
#print(priorprH1)
mH11="assessing the probability that phi_w > .5"
mH12=" "
cat(mH11,mH12,"\n")
mH1prior="prior"
mH1post="posterior"
cat(mH1prior,"  ",mH1post,"\n")
cat(priorprH1,"  ",prH1,"\n") 
if ((prH1==1)|(priorprH1==0)){
minf1="Bayes factor BF10 for phi_w >.5 is approaching"
minf2="infinity"
cat(minf1,minf2,"\n")} else {
BF10=(prH1*(1-priorprH1))/(priorprH1*(1-prH1))
mBF1="Bayes factor BF10 for phi_w > .5"
mBF2="is"
cat(mBF1,mBF2,"\n")
print(BF10)}
    m1X=" "
    m2X=" "
  return(cat(m1X,m2X,"\n"))}

if ((method!="large")&(method!="small")) {
stop("method must be included, and it must equal either the word small or large")} else {}
}

xxxxxxxxx Following the code for dfba_kendall_tau

dfba_kendall_tau<-function(x, y,a0=1,b0=1){
#computes Kendall's tau_a and tau_b rank based coefficients,
#along with the phi_c the concordance parameter where
#phi_c is (1+tau_a)/2.
#The function also finds the number of concordant changes n_c 
#and the number of discordance change.
#The tau_b coefficient is (n_c-n_d)/sqrt([(.5*(n*(n-1)-T_x]*(.5(n*(n-1)-T_y])
#where T_x is the number of lost comparisons due to ties in the x variate and
#T_y is the corresponding lost comparisons due to ties in the y variate.
#The tau_b coefficient does not adjust for excessively correcting for multiply
#tied pairs. However,tau_a coefficient is simply equal to (n_c-n_d)/(n_c+n_d) and
#this coefficent properly adjusts for all tied values. If the are no tied value
#tau_a and tau_b are equal.
 
if ((a0<=0) | (b0<=0)){
a0=1
b0=1
message("a0 and b0 shape parameters cannot be negative, so the default values were used.")} 
else {}
  

l1=length(x)
l2=length(y)
if (l1!=l2) {
stop("The two variate have unequal length. The x and y variates must be paired.")} 
else {}

Xtest=x
Ytest=y
Xtemp=Xtest
Ytemp=Ytest
jc=0
for (j in 1:length(Xtest)){
if ((is.na(Xtemp[j]))|(is.na(Ytemp[j]))) {} else {
jc=jc+1
Xtest[jc]=Xtemp[j]
Ytest[jc]=Ytemp[j]
} }
x=Xtest[1:jc]
y=Ytest[1:jc]


xy<-data.frame(x,y)
x_ties<-table(x)[table(x)>1]
y_ties<-table(y)[table(y)>1]
xy_ties<-table(xy)[table(xy)>1]
t_xi<-unname(table(x)[table(x)>1])
t_yi<-unname(table(y)[table(y)>1])
t_xyi<-unname(table(xy)[table(xy)>1])
Tx<-sum((t_xi*(t_xi-1))/2)
Ty<-sum((t_yi*(t_yi-1))/2)
Txy<-sum(t_xyi*(t_xyi-1)/2)
n<-length(x)
n_max<-n*(n-1)/2-Tx-Ty+Txy
xy_ranks<-data.frame(xrank=rank(xy$x, ties.method="average"),
                     yrank=rank(xy$y, ties.method="average"))
xy_c<-xy_ranks[order(x, -y),] # for n_c, sort on ascending x then descending y
xy$concordant<-rep(NA, nrow(xy))
 for (i in 1:nrow(xy-1)){
  xy$concordant[i]<-sum(xy_c$yrank[(i+1):length(xy_c$yrank)]>xy_c$yrank[i])
}
nc<-sum(xy$concordant, na.rm=TRUE)
nd<-n_max-nc

Tau_a<-(nc-nd)/n_max
Tau_b<-(nc-nd)/sqrt((n*(n-1)/2-Tx)*(n*(n-1)/2-Ty))
phi_c<-nc/(nc+nd)

m1="Frequentist point estimates for tau_a and tau_b are"
m2=":"
cat(m1,m2,"\n")
cat("tau_a","      ","tau_b","\n")
cat(Tau_a," ",Tau_b,"\n")
cat(" ","   ","\n")
m21="Sample concordant n_c and discordant differences are"
cat(m21,m2,"\n")
cat("n_c","  ","n_d","\n")
cat(nc,"  ",nd,"\n")
cat(" ","   ","\n")
m31="Bayesian analysis deal with the concordance proportion"
m32="phi_c"
cat(m31,m32,"\n")
m41="posterior mean and median phi_c are"
cat(m41,m2,"\n")
cat("mean","      ","median","\n")
apost=nc+a0
bpost=nd+b0
postphimean=apost/(apost+bpost)
postphimedian=qbeta(.5,apost,bpost)
cat(postphimean,"  ",postphimedian,"\n")
cat("  "," ","\n")
m51="Corresponding posterior mean and median for tau_a are"
cat(m51,m2,"\n")
cat("mean","      ","median","\n")
tau_a_mean=(2*postphimean)-1
tau_a_median=(2*postphimedian)-1
cat(tau_a_mean,"  ",tau_a_median,"\n")
cat("  "," ","\n")
m61="Beta shape parameters for the phi_c distribution are"
cat(m61,m2,"\n")
cat("a","   ","b","\n")
cat(apost," ",bpost,"\n")
cat("  "," ","\n")

a=apost
b=bpost
qlequal=qbeta(.025,a,b)
qhequal=qbeta(.975,a,b)

met1="phi_c equal-tail 95-percent limit values are"
met2=":"
cat(met1,met2,"\n")
cat(qlequal," ",qhequal,"\n")

alphaL=seq(0,.05,.05/1000)
qL=qbeta(alphaL,a,b)
qH=qbeta(.95+alphaL,a,b)
diff=qH-qL
I=1
mindiff=min(diff)
while (diff[I]>mindiff){
I=I+1}
qLmin=qL[I]
qHmax=qH[I]
mhdi1="phi_c 95-percent highest density limits are"
mhdi2=":"
cat(mhdi1,mhdi2,"\n")
cat(qLmin," ",qHmax,"\n")
cat("  "," ","\n")
cat("The corresponding tau_a interval"," ","\n")
met1="tau_a equal-tail 95-percent limit values are"
met2=":"
cat(met1,met2,"\n")
lowval=(qlequal*2)-1
hival=(qhequal*2)-1
cat(lowval," ",hival,"\n")
met1a="tau_a 95-percent highest density limit values are"
met2a=":"
cat(met1a,met2a,"\n")
lowvalhdi=(qLmin*2)-1
hivalhdi=(qHmax*2)-1
cat(lowvalhdi," ",hivalhdi)
cat(" ","  ","\n")

prH1=1-pbeta(.5,a,b)
priorprH1=1-pbeta(.5,a0,b0)
mH11="Probabilities that either phi_c > .5 or tau_a>0"
cat(mH11,"are","\n")


mH1prior="Prior"
mH1post="Posterior"
cat(mH1prior,"  ",mH1post,"\n")
cat(priorprH1,"  ",prH1,"\n") 
if ((prH1==1)|(priorprH1==0)){
minf1="Bayes factor BF10 for phi_c >.5 is approaching"
minf2="infinity"
cat(minf1,minf2,"\n")} else {
BF10=(prH1*(1-priorprH1))/(priorprH1*(1-prH1))
list("Bayes Factor tau_a > 0"=BF10)}
}


